parse href, extract, set form1's EVENTTARGET and EVENTARGUMENT attributes, finally submit form

while last element's href in $x('//*[contains(@class, "linkPagination")]') not null
ignore 1st 2 rows of drug table, & select 2nd column
$x('//table[contains(@class, "drugdescriptinTable")]//tr[3]/td[2]/a')		-- brand link
$x('//table[contains(@class, "drugdescriptinTable")]//tr[4]/td[2]')		-- brand name
$x('//textarea[contains(@id, "tbUses")]/text()')
$x('//textarea[contains(@id, "tbClassOfDrugs")]/text()')
$x('//p[contains(@id,"pMAnufacturer")]/text()')

scrapy shell test:
#scrapy shell 'http://www.medsplan.com/DrugsDescriptionByDisease/Diarrhea'
>>> a = scrapy.FormRequest.from_response(response, 
formdata = {'__EVENTTARGET': 'ctl00$ContentPlaceHolder1$rptrDrugDetails$ctrl0$lnkDetails'}, 
callback = None,
dont_click = True)
>>> fetch(a)

sudo su
cd webScrape
scrapy startproject pharma4
cd pharma4
vi pharma4/spiders/pharma4_spider.py
...
import re
import scrapy
from scrapy.selector import Selector

class Drug4(scrapy.Item):
    Illness = 'Diarrhoea'
    Generic_name = scrapy.Field()
    Description = scrapy.Field()
    Classification = scrapy.Field()
    Trade_name = scrapy.Field()
    Manufacturer = scrapy.Field()

class QuotesSpider(scrapy.Spider):

    name = 'pharma4'

    def process_str(self, str):
        if str:
            str = str.strip(u' .-\t\n\r')
            str = str.replace(u'\r\n\r\n', u', ')
        return str

    def start_requests(self):

        self.start_url = 'http://www.medsplan.com/DrugsDescriptionByDisease/Diarrhea'
        yield scrapy.Request(url = self.start_url, callback = self.parse1)


    def parse1(self, response):

        rows = response.xpath('//table[contains(@class, "drugdescriptinTable")]//tr/td[2]')

        for row in range(0, len(rows) - 1, 2):
                drug = Drug4()
                #self.log("trade name is " + rows[row].xpath('a/text()').extract()[0])
                drug['Trade_name'] = rows[row].xpath('a/text()').extract()[0]
                drug['Generic_name'] = rows[row + 1].xpath('text()').extract()[0]
                drug_link = rows[row].xpath('a/@href').extract()[0]
                #self.log("drug link is " + drug_link)
                mth_expr = re.search("javascript:__doPostBack\('(.*?)','(.*?)'", drug_link)
                a1 = mth_expr.group(1)
                #self.log("a1 is " + a1)
                a2 = mth_expr.group(2)
                yield scrapy.FormRequest.from_response(
                                   response,
                                   formdata = {'__EVENTTARGET': a1, '__EVENTARGUMENT': a2},
                                   meta = {'item' : drug},
                                   callback = self.parse2,
                                   dont_click = True)

        self.iter = 0
        pagi_mrkrs = response.xpath('//*[contains(@class, "linkPagination")]')
        nxt_mrkr = pagi_mrkrs[len(pagi_mrkrs) - 1].xpath('@href').extract()[0]
        #self.log("next marker is " + nxt_mrkr)
        if nxt_mrkr and self.iter <= 10000:
                mth_expr = re.search("javascript:__doPostBack\('(.*?)','(.*?)'", nxt_mrkr)
                a1 = mth_expr.group(1)
                a2 = mth_expr.group(2)
                yield scrapy.FormRequest.from_response(
                                   response,
                                   formdata = {'__EVENTTARGET': a1, '__EVENTARGUMENT': a2},
                                   callback = self.parse1,
                                   dont_click = True)
                self.iter = self.iter + 1

    def parse2(self, response):

        drug = response.meta['item']

        drug['Description'] = response.xpath('//textarea[contains(@id, "tbUses")]/text()').extract()[0]
        drug['Classification'] = response.xpath('//textarea[contains(@id, "tbClassOfDrugs")]/text()').extract()[0]
        drug['Manufacturer'] = response.xpath('//p[contains(@id,"pMAnufacturer")]/text()').extract()[0]

        #clean records before yield
        for i in drug:
            drug[i] = self.process_str(drug[i])

        yield drug

...
scrapy crawl pharma4
scrapy crawl pharma4 --set FEED_URI=output.csv --set FEED_FORMAT=csv